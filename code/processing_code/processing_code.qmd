---
title: "Cleaning/Wrangling/Exploring the Data"
author: "Vijay Panthayi"
date: "2023-08-20"
output: html_document
---


# Processing script

This script contains the code used to clean, wrangle, and explore both data sets.

# Setup

Load needed packages. Make sure they are installed.

```{r}
remove.packages('rlang')
install.packages('rlang')
library(readxl) #for loading Excel files
library(dplyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
library(psych)
library(tidyverse)
```


# Data loading

This will load in the raw data sheets into R.

```{r}
# path to data
# note the use of the here() package and not absolute paths
temp_data <- read.csv(here::here("data","raw_data","Annual_Surface_Temperature_Change.csv"))
forest_data <- read.csv(here::here("data","raw_data","Forest_and_Carbon.csv"))
```


# Check data

First, let's take a look at the data.

```{r}
describe(temp_data)
describe(forest_data)
```

It appears that both data sheets loaded in correctly.

# Cleaning

Next, let's clean up the data before we begin to explore it. Let's start with the Climate Temperature data sheet.

We can see that many columns from the data sheet are unecessary. For example, the ObjectID is just a count of observations and ISO2 and ISO3 are just the abbreviations for each country. Indicator, Unit, Source, CTS_Code, CTS_Name, and CTS_Full_Descriptor contain the same string of characters, respectively, throughout each observation. Let's first make sure this is true, and then we can remove all these columns from our data sheet.

```{r}
unique(temp_data$Indicator)
unique(temp_data$Unit)
unique(temp_data$Source)
unique(temp_data$CTS_Code)
unique(temp_data$CTS_Name)
unique(temp_data$CTS_Full_Descriptor)

#They all contain only one unique value. Since there are no discrepencies, we can remove these columns.

temp_data_1 <- temp_data[,!names(temp_data) %in% c("ObjectID", "ISO2", "ISO3", "Indicator", "Unit", "Source", "CTS_Code", "CTS_Name", "CTS_Full_Descriptor")]
describe(temp_data_1)
```

Now that we have removed the columns with unecessary information, we can further clean this data sheet by removing observations that have no values for some/all temperature readings. This way, we can proceed with exploration and analysis knowing all observations have readings for every year. 

```{r}
is.na(temp_data_1)
temp_data_noNA <- na.omit(temp_data_1)
describe(temp_data_noNA)
```

Finally, there is an observation for the World as a whole which we will not need as it is not a single country. We can remove this observation from the data.

```{r}
temp_data_clean <- temp_data_noNA[!(row.names(temp_data_noNA) %in% "222"),]
describe(temp_data_clean)
```

Now we can look at the Forest data sheet. 

It appears that each country has multiple observations for different Indicators. Let's find out how many indicators there are possible since not all countries are split equally.

```{r}
unique(forest_data$Indicator)
```
There are six different indicators that each country can have: Carbon stocks in forests, Forest area, Index of carbon stocks in forests, Index of forest extent, Land area, and Share of forest area. To make things easier to explore and analyze later, let's separate the forest data sheet into each of these indicators. First, we should remove the observations that group up multiple countries so we do not have repeated data. Luckily, we can do this alongside removing observations with missing values by removing all observations with an NA value after removing the empty columns of CTS_Code, CTS_Name, and CTS_Full_Descriptor. 

```{r}
forest_data_1 <- forest_data[,!names(forest_data) %in% c("CTS_Code", "CTS_Name", "CTS_Full_Descriptor")]
forest_data_2 <- na.omit(forest_data_1)
```

Now that all observations have been removed with NA values alongside those that do not pertain to a single country, we can divide this data sheet into its respective sets based on Indicator.

```{r}
carbon_stock_data <- forest_data_2[forest_data_2$Indicator == 'Carbon stocks in forests',]
forest_area_data <- forest_data_2[forest_data_2$Indicator == 'Forest area',]
carbon_index_data <- forest_data_2[forest_data_2$Indicator == 'Index of carbon stocks in forests',]
forest_index_data <- forest_data_2[forest_data_2$Indicator == 'Index of forest extent',]
land_area_data <- forest_data_2[forest_data_2$Indicator == 'Land area',]
forest_share_data <- forest_data_2[forest_data_2$Indicator == 'Share of forest area',]
```

Now that we have cleaned up and organized the data as we would like before exploring it, we can go ahead and save the new data sets into the processed_data folder.

# Save data 

Finally, we save the clean data as RDS file. 
This preserves coding like factors, characters, numeric, etc.  

```{r}
save_data_location1 <- here::here("data","processed_data", "carbon_stock_data.rds")
save_data_location2 <- here::here("data","processed_data", "forest_area_data.rds")
save_data_location3 <- here::here("data","processed_data", "carbon_index_data.rds")
save_data_location4 <- here::here("data","processed_data", "forest_index_data.rds")
save_data_location5 <- here::here("data","processed_data", "land_area_data.rds")
save_data_location6 <- here::here("data","processed_data", "forest_share_data.rds")
save_data_location7 <- here::here("data","processed_data", "temp_data_clean.rds")
saveRDS(carbon_stock_data, file = save_data_location1)
saveRDS(forest_area_data, file = save_data_location2)
saveRDS(carbon_index_data, file = save_data_location3)
saveRDS(forest_index_data, file = save_data_location4)
saveRDS(land_area_data, file = save_data_location5)
saveRDS(forest_share_data, file = save_data_location6)
saveRDS(temp_data_clean, file = save_data_location7)
```

